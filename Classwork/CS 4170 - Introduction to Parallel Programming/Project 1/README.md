**Summary:** Within this assignment we explored and applied the knowledge of openmp we had learned up to this point. This included many different functions and methods for parallelizing our program to achieve the best stats in speedup, efficiency, and Karp-Flatt. The program we were operating on runs the PSO algorithm, particle swarm optimization. This algorithm attempts to find the maximum by moving many different particles around constantly based on feedback they receive.

**Instructions:** To run this code you will need to do so on OSC by using the provided jobScript.slurm. To make changes to the algorithm for testing you will want to alter ./src/main.cpp and alter Np which is population size of the particles seeking out the highest point, Nd which is the number of present dimensions, Nt which is the number of iterations it undergoes to find the best point from all iterations, and lastly the number of trials which determines how many times each combination is run in the program, which I set at 5.

**Algorithm:** The PSO algorithm is run to find the peak of all points in a function by sending out a desired number of particles who take active feedback and move around the function accordingly until they return with their best possible answer. This function can be fine tuned to the point that it continually gives a better answer, but this would require many resources. For our PSO function we attempted to get as best results as we could without using days worth of resources. To start off we take a number of particles, Np, and we uniformly distribute them in a vector before updating the best known position and initializng velocity. Then while we remain below the number of iterations, Nt, we continue through a loop that uses dimensions and random numbers to update positions and velocities of the particles individually while also constantly updating the best known position for the individual particle as well as the entire swarm as the search continues, before finally returning the best position that was found overall.

**Method:** The only part of the code that was edited for parallelization was within the function PSO(). I tried to add as many #pragma omp parallel sections to portions of the code that could take advantage of the multiple threads available. At one point I experimented with sections briefly, but my performance remained the best while using the parallel for loops. While parallelizing the code I had to pay special attention to variables that were private or that could take advantage of the reduction clause to avoid using atomic/critical sections. I also took advantage of the collapse() statement with my loops to allow nested parallelism for two of the nested for loops. My strategy for approaching this assignment was to stick with what I am comfortable with and then try to implement more of what we learned in class. The issue I encountered was working on code that wasn't mine and trying to figure out exactly how everything performed. I struggled to figure out which variables were being used in certain ways and this in turn made it hard to know which variables were shared, required to be private, or that could take advantage of the reduction clause. I also encountered the issue that once I added for the most part solely parallel for loops, I couldn't get proper performance with other methods of parallelization and ended up having to try to work with those to the best of my ability.

**Discussion & Analysis:** All results are available in both a [CSV](https://gitlab.com/kodywilliamson/cs4170_sp2021_a01_williamson/-/blob/master/Default/results.csv) and [Excel](https://gitlab.com/kodywilliamson/cs4170_sp2021_a01_williamson/-/blob/master/Results/results.xlsx) format. Evaluation was done using the average of 5 trials between the combination of 1-12 threads and population size(Np) from 50-500 in intervals of 50. 
The results I received showed a linear speedup upwards as the number of threads increases and shows little variance between the different population sizes. Since there is little effect from the population sizes we can assume this problem scales well with increasing population sizes and would not be affected much by large problem sizes. With the linear increasing speedup we can also assume that the speedup will continue to increase as threads are added beyond what we tested.
The efficiency of the PSO parallelized is declining linearly as the number of threads continues to increase and shows little variance between the different population sizes. This means that as we continue to use more resources on this algorithm in its current state, we can expect to get less speedup out of each thread added although it continues to increase speedup.
The Karp-Flatt metric shows an initial spike at the lower threads but shows a linear and decreasing pattern beyond 3 threads as threads are added. The different population sizes tend to follow a similar pattern but the three smallest problem sizes have the highest Karp-Flatt metric by 12 threads. The line is somewhat flat and might have just had an original spike in data that might not repeat on further testing but I cannot say with confidence that this problem scales well with problem size using this graph.

<div style="align:center;">

![Linear Speedup](./Results/AverageSpeedupLine.png)
![Surface Speedup](./Results/AverageSpeedupSurface.png)

![Linear Efficiency](./Results/AverageEfficiencyLine.png)
![Surface Efficiency](./Results/AverageEfficiencySurface.png)

![Linear Karp-Flatt](./Results/AverageKarpFlattLine.png)
![Surface Karp-Flatt](./Results/AverageKarpFlattSurface.png)
</div>
